{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoYZi-i1h0aF"
      },
      "source": [
        "optimization techniques :\n",
        "- always use powers of 2 for hyperparameters initialization. for example, in this code, the vocab size for GPT2 tokenizer is 50257 which is not divisible be 2 so increase the vocab size to 50304. even though we have increased the vocab size, we may think that compute time will increase but actually the compute time decreases. because almost all kernals, all operations are done in powers of 2(like getting 32bits of memory per second so if we want to read 33 bits then it will take 2 seconds and also reading 64 bits will take same 2 seconds), but dont increase to much\n",
        "\n",
        "- use @tf.function decorator for custom train, val and test methods in tensorflow or use pytorch.compile(). this will enable graph execution rather than executing in eager mode\n",
        "\n",
        "- use flash attention instead of self attention. the calculations and output are same but flash attention is more optimized. in tensorflow, you can use tensorflow.keras.layers.MultiHeadAttention() with flash_attention=True to enable flash_attention. 'False' to disable or 'None' to automatically decide by keras. or use keras.config.enable_flash_attention() to enable flash attention globally and keras.config.disable_flash_attention() to disable flash attention globally. you will find easiest implementation of flash attention in pytorch using torch.nn.functional.scaled_dot_product_attention().\n",
        "\n",
        "-  use BF16 operations instead of FP32. both operations offer same range but BF16 has slightly lower precision which may affect the performance of the model negatively but its negligible but we get almost 16X speed then using FP32\n",
        "\n",
        "- gradient clipping : clip the optimizer gradients : by clipping the gradients, we basically try to control the gradients from changing too much at once. it will control such that the jump is not higher than the threshold mentioned. clipnorm=1.0 is mostly used. monitoring the norm is a good practice(as the epochs increases, norm should be smoothening, no spikes, which indicates smooth training)\n",
        "\n",
        "- optimizing learning rate(you can use learning rate schedulers like lr_scheduler, cosine_decay, etc), weight decay and beta values of the optmimzer.\n",
        "\n",
        "- batch size is connected with all other hyperparameters\n",
        "\n",
        "- use gradiesnt accumulation when you can't fit big batches into memory\n",
        "for example, lets' say that we can only fit batch size of 32 into the memory but we need to perform training with batch size of 128 in that case we will train with batch size of 32 and only update the gradients after 4 mini batches which means the effective batch size will be 32*4=128\n",
        "\n",
        "- varying batch_size : model is trained with smaller batch size and then gradually increased\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nttSRSuVuym8"
      },
      "source": [
        "resource : https://www.youtube.com/watch?v=l8pRSuU81PU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UKOsrj-YmRYS",
        "outputId": "052167b0-dbfd-4bcc-a428-4a5545ae91a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "n8Oquifso7FU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import transformers\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "t878QM3oiuRC"
      },
      "outputs": [],
      "source": [
        "# model configuration\n",
        "\n",
        "class Config:\n",
        "    vocab_size: int = 50257   #final token(50256) is <|endoftext|> which is used for both BOS(beginning of sentence) and EOS(end of sentence)\n",
        "    n_positions: int = 1024   #context length\n",
        "    n_embed: int = 768  #embedding dimension\n",
        "    n_layer: int = 12   #number of decoder blocks\n",
        "    n_head: int = 12  #number of attention heads inside each block\n",
        "    n_inner: int = None  #dimensionality of inner feed-forward layers. None will set it to 4*n_embed\n",
        "    activation_function: str = 'gelu'  #activation to use inside the feed-forward layers\n",
        "    resid_pdrop: int = 0.1  #dropout for all fully connected layer in decoder block\n",
        "    embed_pdrop: int = 0.1  #dropout for embedding layers\n",
        "    attn_pdrop: int = 0.1   #dropout for attention\n",
        "    layer_norm_epsilon: int = 1e-5  #epsilon for layer normalization\n",
        "    initializer_range: int = 0.02\n",
        "    batch_size: int = 512\n",
        "\n",
        "config=Config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "0-Z-Zsz5qqI0",
        "outputId": "7b31c4d6-a3b0-4c51-d308-ef87fa2b2691"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gpt\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"gpt\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Decoder</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">124,438,272</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ layer_normalization_24               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_projection (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">OutputProjection</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50257</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">38,597,376</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ decoder (\u001b[38;5;33mDecoder\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m768\u001b[0m)           │     \u001b[38;5;34m124,438,272\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ layer_normalization_24               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m768\u001b[0m)           │           \u001b[38;5;34m1,536\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_projection (\u001b[38;5;33mOutputProjection\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m50257\u001b[0m)         │      \u001b[38;5;34m38,597,376\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">124,439,808</span> (474.70 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m124,439,808\u001b[0m (474.70 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">124,439,808</span> (474.70 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m124,439,808\u001b[0m (474.70 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "tf.keras.mixed_precision.set_global_policy('float32')\n",
        "\n",
        "#gpt2  model\n",
        "\n",
        "class FFN(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(FFN, self).__init__()\n",
        "\n",
        "        self.hidden_units = 4*config.n_embed if config.n_inner is None else config.n_inner\n",
        "        self.activation = tf.keras.activations.get(config.activation_function)\n",
        "\n",
        "        self.hidden1 = tf.keras.layers.Dense(self.hidden_units)\n",
        "        self.final_hidden = tf.keras.layers.Dense(config.n_embed)\n",
        "        self.dropout = tf.keras.layers.Dropout(config.resid_pdrop)\n",
        "\n",
        "    def call(self, input, training=False):\n",
        "        x=self.hidden1(input)\n",
        "        x=self.activation(x, approximate=True)\n",
        "        x=self.final_hidden(x)\n",
        "        x=self.dropout(x, training=training)\n",
        "        return x\n",
        "\n",
        "####################################################################\n",
        "# NOTE : another optimization technique is to use flash attention. pytorch has the best implementation. you can also use tensorflow.keras.layers.MultiHeadAttention(flash_attention=True) and keras.config.enable_flash_attention() to enable flash_attention gloablly or keras.config.disable_flash_attention() to disable flash_attention globally\n",
        "######################################################################\n",
        "# the attention layer in gpt2 is slightly different then tf.keras.layers.MultiHeadAttention() because in gpt2's attention combines QKV projections and then split.\n",
        "class GPT2Attention(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.c_attn = tf.keras.layers.Dense(3*config.n_embed)  # 3*768 for QKV\n",
        "        self.c_proj = tf.keras.layers.Dense(config.n_embed)\n",
        "        self.dropout = tf.keras.layers.Dropout(0.1)\n",
        "\n",
        "    def split_heads(self, x):\n",
        "        head_dim=config.n_embed//config.n_head\n",
        "        return tf.transpose(tf.reshape(x, (tf.shape(x)[0], tf.shape(x)[1], config.n_head, head_dim)), (0, 2, 1, 3))\n",
        "\n",
        "    def call(self, x):\n",
        "        \"\"\"use flash attention\"\"\"\n",
        "        batch_size = tf.shape(x)[0]\n",
        "        qkv = self.c_attn(x)\n",
        "        q, k, v = tf.split(qkv, 3, axis=-1)\n",
        "        q, k, v = self.split_heads(q), self.split_heads(k), self.split_heads(v)\n",
        "\n",
        "        attn = tf.matmul(q, k, transpose_b=True)/tf.sqrt(64.0)\n",
        "        attn = tf.nn.softmax(attn, axis=-1)\n",
        "        attn = self.dropout(attn)\n",
        "\n",
        "        x = tf.matmul(attn, v)\n",
        "        x = tf.reshape(tf.transpose(x, (0, 2, 1, 3)), (batch_size, -1, config.n_embed))\n",
        "        return self.c_proj(x)\n",
        "\n",
        "class DecoderBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(DecoderBlock, self).__init__()\n",
        "\n",
        "        self.attention = GPT2Attention()\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=config.layer_norm_epsilon)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=config.layer_norm_epsilon)\n",
        "\n",
        "        self.ffn = FFN()\n",
        "\n",
        "    def call(self, input, training=False):\n",
        "        x=self.layernorm1(input)\n",
        "        x=self.attention(x)\n",
        "        # skip connection\n",
        "        sk1=x+input\n",
        "        x=self.layernorm2(sk1)\n",
        "        x=self.ffn(x, training=training)\n",
        "        # skip connection\n",
        "        sk2=x+sk1\n",
        "\n",
        "        return sk2\n",
        "\n",
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.embedding=tf.keras.layers.Embedding(\n",
        "            input_dim=config.vocab_size,\n",
        "            output_dim=config.n_embed,\n",
        "            embeddings_initializer=tf.keras.initializers.GlorotUniform()\n",
        "        )\n",
        "\n",
        "        self.pos_embedding=tf.keras.layers.Embedding(\n",
        "            input_dim=config.n_positions,\n",
        "            output_dim=config.n_embed,\n",
        "            embeddings_initializer=tf.keras.initializers.GlorotUniform()\n",
        "        )\n",
        "\n",
        "        self.decoder_blocks=[DecoderBlock() for _ in range(config.n_layer)]\n",
        "\n",
        "    def call(self, input, training=False):\n",
        "\n",
        "        # token embedding\n",
        "        x1 = self.embedding(input)\n",
        "        # position embedding\n",
        "        seq_length=tf.shape(input)[1]\n",
        "        batch_size=tf.shape(input)[0]\n",
        "        pos_ids=tf.range(seq_length)\n",
        "        pos_ids=tf.expand_dims(pos_ids, 0)\n",
        "        pos_ids=tf.tile(pos_ids, [batch_size, 1])\n",
        "        # pos_ids=np.resize(np.arange(input.shape[1]), input.shape)\n",
        "        # pos_ids=np.resize(np.arange(input.shape[1]), config.batch_size*input.shape[1])\n",
        "        # pos_ids=pos_ids.reshape((config.batch_size, config.n_positions))\n",
        "        x2=self.pos_embedding(pos_ids)\n",
        "        # merging the position embeddings\n",
        "        x=x1+x2\n",
        "\n",
        "        # decoder blocks\n",
        "        for block in self.decoder_blocks:\n",
        "            x=block(x, training=training)\n",
        "\n",
        "        return x\n",
        "\n",
        "# for weight tying\n",
        "class OutputProjection(tf.keras.layers.Layer):\n",
        "    def __init__(self, embedding_layer):\n",
        "        super(OutputProjection, self).__init__()\n",
        "        self.embedding_layer=embedding_layer\n",
        "    def call(self, x):\n",
        "        return tf.matmul(x, self.embedding_layer.embeddings, transpose_b=True)\n",
        "\n",
        "\n",
        "class GPT(tf.keras.models.Model):\n",
        "    def __init__(self):\n",
        "        super(GPT, self).__init__()\n",
        "        self.decoder=Decoder()\n",
        "        self.final_layernorm=tf.keras.layers.LayerNormalization(epsilon=config.layer_norm_epsilon)\n",
        "        self.output_projection=OutputProjection(self.decoder.embedding)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.input_layer = tf.keras.layers.Input(shape=input_shape[1:])\n",
        "        _ = self.call(self.input_layer)\n",
        "        super(GPT, self).build(input_shape)\n",
        "\n",
        "    def call(self, input, training=False):\n",
        "        x=self.decoder(input, training=training)\n",
        "        # final layer normalization\n",
        "        x=self.final_layernorm(x)\n",
        "\n",
        "        # GPT2 uses weight tying, where we use the same weights of embedding layer to the final output dense layer to reduce the number of parameters. to achieve this, we perform matrix multiplication on the decoder's final output to the transpose of embedding layer's weights to get the logits.\n",
        "        logits=self.output_projection(x)\n",
        "\n",
        "        return logits\n",
        "\n",
        "    @tf.function   #boosts performance by executing in graph model rather than eager mode(default). also use in inference methods like test_step()\n",
        "    def train_step(self, data):\n",
        "        \"\"\"custom training methos\"\"\"\n",
        "        loss=0.0\n",
        "        inputs, targets=data\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits=self.call(inputs, training=True)\n",
        "            loss=self.compute_loss(x=inputs, y=targets, y_pred=logits)  #we will only use last token to calcualte the loss because only the last token is predicted using all the input tokens or consider it as the prediction of next token given the input tokens. it is taken cared at custom loss function\n",
        "        # compute gradients\n",
        "        gradients=tape.gradient(loss, self.trainable_variables)\n",
        "        # apply gradients\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "\n",
        "        return {'loss': loss}\n",
        "\n",
        "    @tf.function\n",
        "    def on_validation(self, data):\n",
        "        \"\"\"custom validation\"\"\"\n",
        "        val_loss=0.0\n",
        "        inputs, targets=data\n",
        "        logits=self.call(inputs, training=False)\n",
        "        val_loss=self.compute_loss(x=inputs, y=targets, y_pred=logits)\n",
        "        return {'val_loss': val_loss}\n",
        "\n",
        "\n",
        "model=GPT()\n",
        "model.build(input_shape=(config.batch_size, config.n_positions))\n",
        "print(model.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483,
          "referenced_widgets": [
            "f2fa0da3f123493d85ec704a0526b14a",
            "1f2c6bda17294c42ab70d46d8982ed89",
            "e81e27dde3ec4c799529ad9915422466",
            "b37b4cf15b9b438cb1806a86bef24b1a",
            "18b3966d660246c7a8ec4045fa4e0582",
            "5830eb63388b4377b166e5a7b2dad9a4",
            "bb98b4da6a184a5bb02bfcf7fb563545",
            "d4903471f6d4419c83f88d663f45d33c",
            "e4de88b8c16c468c9dfe7554fc604314",
            "51835936b0ad48baa4aaed58ab48ad41",
            "07fc45be19f94345868df48f7bd2f8ea",
            "5b7311ff285a4528a1cc8c58d5423184",
            "6ca11b0c28384e1e96afb21dda3693df",
            "dbf01cd08ed64e9ea8c2cd7365d32e56",
            "26ffc4e8f6754c909bd1d302b0d73aeb",
            "eacaa9b644224425b8c6bc245d1b04c0",
            "46b9ef0f3784402484875828cb622a3a",
            "8c656addc14347fda2e6b2cf36d28230",
            "2f50b105992847158401f5f7ecbdb4e2",
            "dc2fbf0e6df545fcbac35ece235ca5a0",
            "7d87fe850b004e3582cde8f783492047",
            "5e9c984bb9cd4e558c1f66a2bc09204f"
          ]
        },
        "id": "fWJTUk8cHFIv",
        "outputId": "c80c5aa3-4409-40be-8514-368ad2c99996"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2fa0da3f123493d85ec704a0526b14a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b7311ff285a4528a1cc8c58d5423184",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFGPT2Model.\n",
            "\n",
            "All the weights of TFGPT2Model were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"tfgpt2_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " transformer (TFGPT2MainLay  multiple                  124439808 \n",
            " er)                                                             \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 124439808 (474.70 MB)\n",
            "Trainable params: 124439808 (474.70 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "gpt=transformers.TFGPT2Model.from_pretrained('gpt2')\n",
        "gpt.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PC9TPBGcNCkX"
      },
      "source": [
        "number of paramters from our model and gpt model are exactly matching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ti_9DsLU5ZeJ"
      },
      "outputs": [],
      "source": [
        "def load_weights(model, gpt):\n",
        "\n",
        "    # all layer names and weights of the respective layers from huggingface gpt2-small\n",
        "    gpt_layer_name=[i.name for i in gpt.layers[0].submodules]\n",
        "    gpt_weights=[i.weights for i in gpt.layers[0].submodules]\n",
        "\n",
        "    # setting weights\n",
        "    # embedding layer\n",
        "    model.decoder.embedding.set_weights([gpt_weights[gpt_layer_name.index('wte')][0].numpy()])\n",
        "    # position embedding layer\n",
        "    model.decoder.pos_embedding.set_weights([gpt_weights[gpt_layer_name.index('wpe')][0].numpy()])\n",
        "\n",
        "    # decoder blocks\n",
        "    for i in range(config.n_layer):\n",
        "        weights=gpt_weights[gpt_layer_name.index(f'h_._{i}')]\n",
        "        # layernorm1 weights\n",
        "        gamma=weights[0].numpy()\n",
        "        beta=weights[1].numpy()\n",
        "        model.decoder.decoder_blocks[i].layernorm1.set_weights([gamma, beta])\n",
        "        # layernrom2 weights\n",
        "        gamma=weights[6].numpy()\n",
        "        beta=weights[7].numpy()\n",
        "        model.decoder.decoder_blocks[i].layernorm2.set_weights([gamma, beta])\n",
        "        # attention weights\n",
        "        c_attn_weights=weights[2].numpy()\n",
        "        c_attn_bias=weights[3].numpy()\n",
        "        c_proj_weights=weights[4].numpy()\n",
        "        c_proj_bias=weights[5].numpy()\n",
        "        model.decoder.decoder_blocks[i].attention.c_attn.set_weights(\n",
        "            [c_attn_weights, c_attn_bias.reshape((c_attn_bias.shape[1]))]\n",
        "        )\n",
        "        model.decoder.decoder_blocks[i].attention.c_proj.set_weights(\n",
        "            [c_proj_weights, c_proj_bias.reshape((c_proj_bias.shape[1]))]\n",
        "        )\n",
        "        # feed forward layer weights\n",
        "        c_fc_weights=weights[8].numpy()\n",
        "        c_fc_bias=weights[9].numpy()\n",
        "        c_proj_weights=weights[10].numpy()\n",
        "        c_proj_bias=weights[11].numpy()\n",
        "        model.decoder.decoder_blocks[i].ffn.hidden1.set_weights(\n",
        "            [c_fc_weights, c_fc_bias.reshape((c_fc_bias.shape[1]))]\n",
        "        )\n",
        "        model.decoder.decoder_blocks[i].ffn.final_hidden.set_weights(\n",
        "            [c_proj_weights, c_proj_bias.reshape((c_proj_bias.shape[1]))]\n",
        "        )\n",
        "\n",
        "    # final layer normalization weights\n",
        "    gamma=gpt_weights[gpt_layer_name.index('ln_f')][0].numpy()\n",
        "    beta=gpt_weights[gpt_layer_name.index('ln_f')][1].numpy()\n",
        "    model.final_layernorm.set_weights([gamma, beta])\n",
        "\n",
        "    return model\n",
        "\n",
        "model=load_weights(model, gpt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "6721697c1c68466cbfbbdd16449372b0",
            "667a8a9ac3e845a6b1d6891f8baf8852",
            "09eeb6283403453a99bf8f9e92d66d5e",
            "5f9cdbc2f0e9489083cd3feba9102f9a",
            "7fe3c43d2a3f4cbd980c5a70f1d088a2",
            "bd7186fcbfe54b0f9c5adbf467266adc",
            "9a0df6faa8874ef98a9a7aaa4be8d2be",
            "65013a9665bb4440a100e3b5944bbeff",
            "e897b57afab246a28aaa48c62938fb81",
            "f39b1a1844f14a639feca16a9cbe2bef",
            "e7d01eaa625b4b3d9b6879081111d899",
            "ef52a8345ed9431cbe8eff251407d5a0",
            "db457bcf5bfe4ba598d4a06e7b7882df",
            "f7c2f72cba374a5e8982fc64287e9246",
            "2233d696f61b482898e2cb84115d57d7",
            "fa0a452cee0a4a7f83452f6134b6e774",
            "c75cf111d4864e67b1b450544ea8e4a2",
            "cc85aa1ad6fa4c908fc828fd9ed3f489",
            "e2f64ccfefb245f28aabef5c8a555b07",
            "5866ff80fcc94ffbbeb170dfd5100148",
            "763b2f16d27a49d5947fc6338de1a24a",
            "a4316c8baa0545dc95e0fdaaaf6801b2",
            "3c879867a4af448ca931cbd2e93ac420",
            "98bc657924a240c4b9924d49f06308f3",
            "4fccc1d4b77f487dad21ebc52a8afb97",
            "bd96943a8aa248e3aac5beea743fc541",
            "4baeed08cc5348c5b21f312c0cbee154",
            "677ccb9c83d946a68b8fe2180e840a0c",
            "e83132e7be1e461faf7a8f380152f376",
            "b051fbbf949e4700915f46968bdfe117",
            "5afd0d46c74046369e99fd25d5fc736d",
            "949175170ca6485d8c0bea03513d98f4",
            "ce305ff9cf3747239ac650123aec531a",
            "74d5ece3f3d244e4b4edf8f62b89f9c2",
            "6834e1b57a844f558da7cc9b34806658",
            "7814329c9ed24a4f877396bfcfce0c1e",
            "b453afe8c76b470f8f57be23ba501d7f",
            "4cf617d36651419e9e734b7248aa9685",
            "1db28ea904b945a9945e5b6020a2b34a",
            "530256dcba494eb58f1fceda4e265148",
            "840184f87c7e4a78b4c09463c78df88f",
            "76894766b40b4c959a5c296cb1a4dc1f",
            "457f9aadc31741f3aa21c08588799283",
            "dac2474a8fbc40eb84f158007777d0d7"
          ]
        },
        "id": "a1Z5148jrHre",
        "outputId": "9bd6de3e-691c-439c-acab-bbb855b312b1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6721697c1c68466cbfbbdd16449372b0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef52a8345ed9431cbe8eff251407d5a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c879867a4af448ca931cbd2e93ac420",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74d5ece3f3d244e4b4edf8f62b89f9c2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# gpt2 tokenizer - you either load the tokenizer from huggingface or use tiktoken(OpenAI's official library)\n",
        "# we are going to use from huggingface\n",
        "tokenizer=transformers.AutoTokenizer.from_pretrained('gpt2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQmCHMc0Q5UA",
        "outputId": "fae69887-7e69-4cc3-f5db-85e9f5ff3a76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "original text : what is computer?\n",
            "encoded sequence : [[10919   318  3644    30]]\n",
            "input shape : (1, 4)\n",
            "predicted tokens : [[  11  340   30 3644]]\n",
            "predicted sequence : , it? computer\n",
            "output logits shape : (1, 4, 50257)\t output shape : (1, 4)\n"
          ]
        }
      ],
      "source": [
        "text='what is computer?'\n",
        "seq=tokenizer(text)['input_ids']\n",
        "seq=np.array(seq).reshape((1, len(seq)))\n",
        "# logits prediction\n",
        "logits=model.predict(seq, verbose=0)\n",
        "# softmax\n",
        "ypred=tf.nn.softmax(logits)\n",
        "ypred=tf.argmax(ypred, axis=-1)\n",
        "ypred_decoded = tokenizer.decode(ypred[0])\n",
        "\n",
        "print(f'original text : {text}')\n",
        "print(f'encoded sequence : {seq}')\n",
        "print(f'input shape : {seq.shape}')\n",
        "print(f'predicted tokens : {ypred}')\n",
        "print(f'predicted sequence : {ypred_decoded}')\n",
        "print(f'output logits shape : {logits.shape}\\t output shape : {ypred.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBUIhuizRpzo"
      },
      "source": [
        "in the output ',' is predicted using 'what' from input, 'it' is predicted using 'what' and 'is' from input and so on till last output token is predicted using all of the input tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E14bHW-PTlge",
        "outputId": "bc9aa3ca-a845-4454-9281-28de93fe3814"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sample text : Hello, I'm a super star who like to\n",
            "top 5 samples : \n",
            "sequence 1 - \r star who who star, star, star, star, star I, star Star,, a Star a Star, Star Star a Star a Star Star\n",
            "sequence 2 - \r be, I'm a, who super who super star I who star Star, I Star, star, star a super star, star, superstar\n",
            "sequence 3 - \r like like star, who'm a I to I I super, Star super I a star who, who super to Super, to super to Super a\n",
            "sequence 4 - \r love a super like to am I who a stars to Star to super Super star who super I super I, super star to who, super star star\n",
            "sequence 5 - \r have I to to I to to and I Star who stars a. I to to to to Super to Super who a a I Super who a,\n"
          ]
        }
      ],
      "source": [
        "# sample text generation\n",
        "sample=\"Hello, I'm a super star who like to\"\n",
        "max_length=30\n",
        "temperature=1.5  # to control the randomness of the output. balance between coherence and creativity.\n",
        "# low temperature(<1.0 - like 0.1, 0.2, etc) - picks the most probable output(the best but the options/variety will be low) - best for most accurate answers\n",
        "# high temperature(>1.0 - like 1.5, 1.6, etc) - picks less probable but adds more variety to the output(not the best but creative) - most suited for creative writing tasks, etc\n",
        "# default temperature - 1.0\n",
        "\n",
        "top_k=5  # select top-5 outputs\n",
        "\n",
        "seq = tokenizer(sample)['input_ids']\n",
        "topk_outputs=[]\n",
        "\n",
        "for i in range(max_length):\n",
        "    input=seq[-config.n_positions:]\n",
        "    input=np.array(input).reshape((1, len(input)))\n",
        "\n",
        "    logits=model(input)\n",
        "    scaled_logits=logits/temperature\n",
        "    scaled_logits=scaled_logits[0, -1, :] #selecting the last token\n",
        "    # top_k predictions with their indices\n",
        "    top_k_logits, top_k_indices = tf.math.top_k(scaled_logits, k=top_k)\n",
        "    topk_outputs.append(top_k_indices.numpy())\n",
        "\n",
        "    # probability of the top_k selected predictions\n",
        "    top_k_proba = tf.nn.softmax(top_k_logits).numpy()\n",
        "    # next token selection\n",
        "    next_token = np.random.choice(top_k_indices.numpy(), p=top_k_proba)\n",
        "    seq.append(next_token)\n",
        "\n",
        "\n",
        "print(f'sample text : {sample}')\n",
        "print(f'top {top_k} samples : ')\n",
        "# decoding the sequences\n",
        "for i in range(top_k):\n",
        "    seq = tokenizer.decode(np.array(topk_outputs)[:, i])\n",
        "    print(f'sequence {i+1} - \\r{seq}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv2dlzsZQXHK"
      },
      "source": [
        "the model is not yet fine-tuned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPmYXADgT_GQ"
      },
      "source": [
        "## Micro GPT\n",
        "\n",
        "we will build a smaller version of GPT2 to pre-train and fine-tune it with some data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1ue5-JmgUfmt"
      },
      "outputs": [],
      "source": [
        "config=Config()\n",
        "# new model parameters\n",
        "config.vocab_size=50307\n",
        "config.n_positions=128  #context length\n",
        "config.n_embed=64   #embedding dimension\n",
        "config.n_layer=4  #decoder blocks\n",
        "config.n_head=4   #attention heads in each block\n",
        "config.n_inner=None\n",
        "config.activation_function='gelu'\n",
        "config.resid_pdrop=0.15   #dropout\n",
        "config.embed_pdrop=0.15  #dropout for embedding layers\n",
        "config.attn_pdrop=0.15   #dropout for attention\n",
        "config.layer_norm_epsilon=1e-5\n",
        "config.initializer_range=0.02\n",
        "config.batch_size=64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "UyalFRDUVj7u",
        "outputId": "621acb72-49d1-403d-80a2-770604a31366"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gpt_3\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"gpt_3\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ decoder_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Decoder</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,427,776</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ layer_normalization_51               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_projection_3                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50307</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,219,648</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">OutputProjection</span>)                   │                             │                 │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ decoder_3 (\u001b[38;5;33mDecoder\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m3,427,776\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ layer_normalization_51               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ output_projection_3                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m50307\u001b[0m)          │       \u001b[38;5;34m3,219,648\u001b[0m │\n",
              "│ (\u001b[38;5;33mOutputProjection\u001b[0m)                   │                             │                 │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,427,904</span> (13.08 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,427,904\u001b[0m (13.08 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,427,904</span> (13.08 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,427,904\u001b[0m (13.08 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "tf.keras.mixed_precision.set_global_policy('float32')\n",
        "\n",
        "model=GPT()\n",
        "model.build(input_shape=(config.batch_size, config.n_positions))\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqqwzR2vVsH5"
      },
      "source": [
        "micro GPT has ~3.5 million parameters only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1eAwHedVpEV",
        "outputId": "59115d42-73aa-4b56-c076-3e74fe3d907d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-02-16 04:15:09--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-02-16 04:15:10 (25.4 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# downloading tiny shakesphere dataset\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GgTY0EgYzzM",
        "outputId": "d0f2e6c7-f51f-4a40-d35d-781345e1e447"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (338025 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(338024, 128) (338024, 1)\n"
          ]
        }
      ],
      "source": [
        "with open('./input.txt', 'r', encoding='utf-8') as f:\n",
        "    data=f.read()\n",
        "data=tokenizer(data)['input_ids']\n",
        "\n",
        "x=[]\n",
        "y=[]\n",
        "\n",
        "for i in range(1, len(data)):\n",
        "    seq=data[:i][-config.n_positions:]\n",
        "    x.append(seq)\n",
        "    y.append(data[i])\n",
        "\n",
        "x=tf.keras.preprocessing.sequence.pad_sequences(x, padding='post', maxlen=config.n_positions)\n",
        "y=np.array(y).reshape((-1, 1))\n",
        "\n",
        "print(x.shape, y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "1m4TZdCLk9gJ"
      },
      "outputs": [],
      "source": [
        "def custom_loss(ytrue, ypred):\n",
        "    \"\"\"custom loss function to consider only the final token from logits\"\"\"\n",
        "    return tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)(ytrue, ypred[:, -1, :])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.AdamW(learning_rate=3e-4, beta_1=0.90, beta_2=0.95, epsilon=1e-8, clipnorm=1.0, weight_decay=0.1),    #GPT2 used beta1=0.9, beta2=0.95, eposilon=1e-8, clipnorm=1.0, learning_rate=3e-4\n",
        "    loss=custom_loss\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k12Rwu-Juffw",
        "outputId": "dade576e-f3c1-4053-f351-2e0caff4505f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<DTypePolicy \"mixed_bfloat16\">\n"
          ]
        }
      ],
      "source": [
        "# enable TF32 instead of using FP32 for floating point calculation. using TF32 boosts the speed ~8x then FP32. TF32 is lower precision than FP32 but its negligible so performance is not affected much. use tensorflow math functions instead of numpy as much as possible to take full advantage of it.\n",
        "tf.config.experimental.enable_tensor_float_32_execution(False)\n",
        "# to make the computation more faster, we will switch to BF16. here also the signed bits/exponent bits is unchanged(same as FP32) so even though the precision is lower then FP32, its very negligible so its 16x faster then FP32 performance drop is also negligible.\n",
        "# to use Bfloat16 :\n",
        "#  set mixed precision policy which will combine FP32 and BF16 so some operations like matrix multiplication and convolutions will use BF16 and other operations will use FP32\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_bfloat16')\n",
        "# verification\n",
        "print(tf.keras.mixed_precision.global_policy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlbmZLOnwW64"
      },
      "source": [
        "![text](/content/img.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rECa_eLy3dAc",
        "outputId": "99e0fe26-4177-40a4-c884-c741cd740c57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 473ms/step - loss: 6.1857\n",
            "Epoch 2/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 5.6876\n",
            "Epoch 3/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - loss: 5.4282\n",
            "Epoch 4/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 5.2854\n",
            "Epoch 5/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 5.2381\n",
            "Epoch 6/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 5.1830\n",
            "Epoch 7/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - loss: 5.1568\n",
            "Epoch 8/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 5.1317\n",
            "Epoch 9/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 5.0603\n",
            "Epoch 10/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - loss: 5.0207\n",
            "Epoch 11/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 4.9866\n",
            "Epoch 12/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - loss: 4.9499\n",
            "Epoch 13/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 4.9119\n",
            "Epoch 14/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - loss: 4.8603\n",
            "Epoch 15/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 4.8312\n",
            "Epoch 16/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 4.8229\n",
            "Epoch 17/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 4.7915\n",
            "Epoch 18/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 4.7716\n",
            "Epoch 19/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 4.7279\n",
            "Epoch 20/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - loss: 4.6972\n",
            "Epoch 21/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 4.6599\n",
            "Epoch 22/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - loss: 4.6364\n",
            "Epoch 23/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - loss: 4.5754\n",
            "Epoch 24/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 4.5645\n",
            "Epoch 25/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 4.5086\n",
            "Epoch 26/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 4.4620\n",
            "Epoch 27/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - loss: 4.4346\n",
            "Epoch 28/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 4.3761\n",
            "Epoch 29/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - loss: 4.3458\n",
            "Epoch 30/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 4.3079\n",
            "Epoch 31/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - loss: 4.2389\n",
            "Epoch 32/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 4.2359\n",
            "Epoch 33/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - loss: 4.1919\n",
            "Epoch 34/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 4.1507\n",
            "Epoch 35/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - loss: 4.1139\n",
            "Epoch 36/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 4.0667\n",
            "Epoch 37/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 4.0260\n",
            "Epoch 38/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - loss: 4.0148\n",
            "Epoch 39/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - loss: 3.9386\n",
            "Epoch 40/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - loss: 3.9241\n",
            "Epoch 41/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - loss: 3.8692\n",
            "Epoch 42/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - loss: 3.8442\n",
            "Epoch 43/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 3.7601\n",
            "Epoch 44/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - loss: 3.7529\n",
            "Epoch 45/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 3.6799\n",
            "Epoch 46/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - loss: 3.6790\n",
            "Epoch 47/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 3.6383\n",
            "Epoch 48/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - loss: 3.5816\n",
            "Epoch 49/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 3.5289\n",
            "Epoch 50/50\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 3.5075\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78123a189d10>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# fitting the model on small subset-bf16\n",
        "model.fit(x[:2000], y[:2000], epochs=50, batch_size=config.batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIJR5r47vxuB",
        "outputId": "db6e64ac-5858-4c5f-f75b-b91de7032126"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch:1/50 | avg.loss/epoch:8.4196215 | time:14.065 | tokens/sec:145.607\n",
            "epoch:2/50 | avg.loss/epoch:8.3361015 | time:2.906 | tokens/sec:704.786\n",
            "epoch:3/50 | avg.loss/epoch:8.2450428 | time:2.873 | tokens/sec:712.833\n",
            "epoch:4/50 | avg.loss/epoch:8.1490850 | time:2.885 | tokens/sec:709.957\n",
            "epoch:5/50 | avg.loss/epoch:8.0501728 | time:2.900 | tokens/sec:706.280\n",
            "epoch:6/50 | avg.loss/epoch:7.9489222 | time:2.950 | tokens/sec:694.230\n",
            "epoch:7/50 | avg.loss/epoch:7.8459454 | time:2.932 | tokens/sec:698.601\n",
            "epoch:8/50 | avg.loss/epoch:7.7420397 | time:2.971 | tokens/sec:689.387\n",
            "epoch:9/50 | avg.loss/epoch:7.6361456 | time:2.995 | tokens/sec:683.834\n",
            "epoch:10/50 | avg.loss/epoch:7.5302601 | time:3.053 | tokens/sec:670.750\n",
            "epoch:11/50 | avg.loss/epoch:7.4247112 | time:3.064 | tokens/sec:668.474\n",
            "epoch:12/50 | avg.loss/epoch:7.3181930 | time:3.147 | tokens/sec:650.741\n",
            "epoch:13/50 | avg.loss/epoch:7.2114353 | time:3.150 | tokens/sec:650.098\n",
            "epoch:14/50 | avg.loss/epoch:7.1056900 | time:5.104 | tokens/sec:401.244\n",
            "epoch:15/50 | avg.loss/epoch:7.0009880 | time:3.085 | tokens/sec:663.916\n",
            "epoch:16/50 | avg.loss/epoch:6.8951125 | time:3.026 | tokens/sec:676.754\n",
            "epoch:17/50 | avg.loss/epoch:6.7907009 | time:3.045 | tokens/sec:672.520\n",
            "epoch:18/50 | avg.loss/epoch:6.6869936 | time:2.993 | tokens/sec:684.272\n",
            "epoch:19/50 | avg.loss/epoch:6.5848675 | time:2.961 | tokens/sec:691.741\n",
            "epoch:20/50 | avg.loss/epoch:6.4842691 | time:2.965 | tokens/sec:690.690\n",
            "epoch:21/50 | avg.loss/epoch:6.3838887 | time:2.976 | tokens/sec:688.091\n",
            "epoch:22/50 | avg.loss/epoch:6.2864094 | time:2.922 | tokens/sec:700.936\n",
            "epoch:23/50 | avg.loss/epoch:6.1877670 | time:2.924 | tokens/sec:700.406\n",
            "epoch:24/50 | avg.loss/epoch:6.0927515 | time:2.909 | tokens/sec:703.909\n",
            "epoch:25/50 | avg.loss/epoch:6.0000467 | time:2.942 | tokens/sec:696.197\n",
            "epoch:26/50 | avg.loss/epoch:5.9092412 | time:2.913 | tokens/sec:702.955\n",
            "epoch:27/50 | avg.loss/epoch:5.8193245 | time:2.903 | tokens/sec:705.429\n",
            "epoch:28/50 | avg.loss/epoch:5.7326732 | time:2.903 | tokens/sec:705.594\n",
            "epoch:29/50 | avg.loss/epoch:5.6470866 | time:2.935 | tokens/sec:697.871\n",
            "epoch:30/50 | avg.loss/epoch:5.5672932 | time:2.894 | tokens/sec:707.747\n",
            "epoch:31/50 | avg.loss/epoch:5.4876213 | time:2.902 | tokens/sec:705.726\n",
            "epoch:32/50 | avg.loss/epoch:5.4124484 | time:2.909 | tokens/sec:704.030\n",
            "epoch:33/50 | avg.loss/epoch:5.3391190 | time:2.949 | tokens/sec:694.584\n",
            "epoch:34/50 | avg.loss/epoch:5.2692003 | time:2.921 | tokens/sec:701.216\n",
            "epoch:35/50 | avg.loss/epoch:5.2027721 | time:2.920 | tokens/sec:701.463\n",
            "epoch:36/50 | avg.loss/epoch:5.1390324 | time:2.951 | tokens/sec:693.917\n",
            "epoch:37/50 | avg.loss/epoch:5.0747108 | time:2.994 | tokens/sec:684.035\n",
            "epoch:38/50 | avg.loss/epoch:5.0156918 | time:2.958 | tokens/sec:692.372\n",
            "epoch:39/50 | avg.loss/epoch:4.9617624 | time:2.949 | tokens/sec:694.503\n",
            "epoch:40/50 | avg.loss/epoch:4.9079790 | time:2.972 | tokens/sec:689.062\n",
            "epoch:41/50 | avg.loss/epoch:4.8573432 | time:3.001 | tokens/sec:682.387\n",
            "epoch:42/50 | avg.loss/epoch:4.8085923 | time:2.983 | tokens/sec:686.500\n",
            "epoch:43/50 | avg.loss/epoch:4.7631106 | time:2.985 | tokens/sec:685.983\n",
            "epoch:44/50 | avg.loss/epoch:4.7191339 | time:5.104 | tokens/sec:401.244\n",
            "epoch:45/50 | avg.loss/epoch:4.6760826 | time:2.992 | tokens/sec:684.525\n",
            "epoch:46/50 | avg.loss/epoch:4.6345425 | time:2.970 | tokens/sec:689.462\n",
            "epoch:47/50 | avg.loss/epoch:4.5935640 | time:5.104 | tokens/sec:401.249\n",
            "epoch:48/50 | avg.loss/epoch:4.5600281 | time:2.990 | tokens/sec:684.907\n",
            "epoch:49/50 | avg.loss/epoch:4.5294876 | time:2.935 | tokens/sec:697.783\n",
            "epoch:50/50 | avg.loss/epoch:4.4989648 | time:2.948 | tokens/sec:694.718\n"
          ]
        }
      ],
      "source": [
        "# custom training loop with gradient accumulation - instead of updating the gradients at every batch, we load smaller batches then calculate the gradients, add them and update the gradients only after accumulating them for total batch size. for example, let total_batch_size=512 but we cant load 512 batch into the memory at the same time so we load batch of 32, calculate the gradients on the mini_batches and add them till we reach batch size of 512 (i.e., we keep adding the gradients 16 times (32*16=512)) and update the optimizer using the accumulated gradients. in this way we can take advantage of using large batch size eventhough we dont have the compute power to handle large batches at the same time. this gradient accumulation can also be used when we want to train the model on increasing batch size like in gpt2/3 where batch size was increasing as the epoch increases.\n",
        "\n",
        "epochs=50\n",
        "total_batch_size=512  #we cant fit this many batches into the memory at once\n",
        "mini_batch_size=64   #larger the total_batch_size and mini_batch_size, more efficient the training is.\n",
        "assert total_batch_size%mini_batch_size==0  #confirm that total batch size is divisible by batch size\n",
        "grad_acum_steps=total_batch_size//mini_batch_size\n",
        "assert len(x[:2048])%total_batch_size==0  #making sure that total batch size is a multiple of total data length\n",
        "steps=len(x[:2048])//total_batch_size  #number of steps to cover entire data for 1 epoch\n",
        "\n",
        "trainset=tf.data.Dataset.from_tensor_slices((x[:2048], y[:2048])).shuffle(buffer_size=16).batch(batch_size=mini_batch_size)\n",
        "\n",
        "tf.keras.mixed_precision.set_global_policy('float32')\n",
        "model=GPT()\n",
        "model.build(input_shape=(config.batch_size, config.n_positions))\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_bfloat16')\n",
        "\n",
        "\n",
        "optimizer=tf.keras.optimizers.AdamW(learning_rate=3e-4, beta_1=0.90, beta_2=0.95, epsilon=1e-8, clipnorm=1.0, weight_decay=0.1)\n",
        "loss_fn=custom_loss\n",
        "\n",
        "@tf.function\n",
        "def train_step(inputs, targets, model, loss_fn, accumulated_gradients, apply_optimizer=False, optimizer=None):\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits=model(inputs, training=True)\n",
        "        loss=loss_fn(targets, logits)\n",
        "    gradients=tape.gradient(loss, model.trainable_variables)\n",
        "    accumulated_gradients=[(accum_grad+grad) for accum_grad, grad in zip(accumulated_gradients,gradients)]\n",
        "\n",
        "    if apply_optimizer:\n",
        "        optimizer.apply_gradients(zip(accumulated_gradients, model.trainable_variables))\n",
        "        return loss\n",
        "\n",
        "\n",
        "    return loss, accumulated_gradients\n",
        "\n",
        "accumulated_gradients=[tf.zeros_like(var) for var in model.trainable_variables]\n",
        "for epoch in range(epochs):\n",
        "    start=time.time()\n",
        "    epoch_loss=0.0\n",
        "\n",
        "    batch_loss=0.0\n",
        "    for step, data in enumerate(trainset):\n",
        "          #to store gradients\n",
        "\n",
        "        inputs, targets=data\n",
        "        if step%grad_acum_steps==0:\n",
        "            loss = train_step(inputs, targets, model, loss_fn, accumulated_gradients, apply_optimizer=True, optimizer=optimizer)\n",
        "            batch_loss+=loss\n",
        "            batch_loss/=grad_acum_steps\n",
        "            epoch_loss+=batch_loss\n",
        "            batch_loss=0.0\n",
        "            accumulated_gradients=[tf.zeros_like(var) for var in model.trainable_variables]\n",
        "            # print(f'updated at {step}')\n",
        "\n",
        "        else:\n",
        "            loss, accumulated_gradients = train_step(inputs, targets, model, loss_fn, accumulated_gradients)\n",
        "            batch_loss+=loss\n",
        "\n",
        "    epoch_loss/=steps\n",
        "    end=time.time()\n",
        "    print(f'epoch:{epoch+1}/{epochs} | avg.loss/epoch:{epoch_loss:.7f} | time:{(end-start):.3f} | tokens/sec:{2048/(end-start):.3f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZU1i2WaXpwSp"
      },
      "source": [
        "this is the pretrained stage of the model. we will then fine-tune the model based on our needs. after then we can check the performance of the model using datasets like helloswag, etc\n",
        "\n",
        "for fine-tuning see ./finetuning.ipynb"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07fc45be19f94345868df48f7bd2f8ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09eeb6283403453a99bf8f9e92d66d5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65013a9665bb4440a100e3b5944bbeff",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e897b57afab246a28aaa48c62938fb81",
            "value": 26
          }
        },
        "18b3966d660246c7a8ec4045fa4e0582": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1db28ea904b945a9945e5b6020a2b34a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f2c6bda17294c42ab70d46d8982ed89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5830eb63388b4377b166e5a7b2dad9a4",
            "placeholder": "​",
            "style": "IPY_MODEL_bb98b4da6a184a5bb02bfcf7fb563545",
            "value": "config.json: 100%"
          }
        },
        "2233d696f61b482898e2cb84115d57d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_763b2f16d27a49d5947fc6338de1a24a",
            "placeholder": "​",
            "style": "IPY_MODEL_a4316c8baa0545dc95e0fdaaaf6801b2",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 5.72MB/s]"
          }
        },
        "26ffc4e8f6754c909bd1d302b0d73aeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d87fe850b004e3582cde8f783492047",
            "placeholder": "​",
            "style": "IPY_MODEL_5e9c984bb9cd4e558c1f66a2bc09204f",
            "value": " 548M/548M [00:03&lt;00:00, 161MB/s]"
          }
        },
        "2f50b105992847158401f5f7ecbdb4e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c879867a4af448ca931cbd2e93ac420": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98bc657924a240c4b9924d49f06308f3",
              "IPY_MODEL_4fccc1d4b77f487dad21ebc52a8afb97",
              "IPY_MODEL_bd96943a8aa248e3aac5beea743fc541"
            ],
            "layout": "IPY_MODEL_4baeed08cc5348c5b21f312c0cbee154"
          }
        },
        "457f9aadc31741f3aa21c08588799283": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46b9ef0f3784402484875828cb622a3a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4baeed08cc5348c5b21f312c0cbee154": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cf617d36651419e9e734b7248aa9685": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fccc1d4b77f487dad21ebc52a8afb97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b051fbbf949e4700915f46968bdfe117",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5afd0d46c74046369e99fd25d5fc736d",
            "value": 456318
          }
        },
        "51835936b0ad48baa4aaed58ab48ad41": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "530256dcba494eb58f1fceda4e265148": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5830eb63388b4377b166e5a7b2dad9a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5866ff80fcc94ffbbeb170dfd5100148": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5afd0d46c74046369e99fd25d5fc736d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b7311ff285a4528a1cc8c58d5423184": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ca11b0c28384e1e96afb21dda3693df",
              "IPY_MODEL_dbf01cd08ed64e9ea8c2cd7365d32e56",
              "IPY_MODEL_26ffc4e8f6754c909bd1d302b0d73aeb"
            ],
            "layout": "IPY_MODEL_eacaa9b644224425b8c6bc245d1b04c0"
          }
        },
        "5e9c984bb9cd4e558c1f66a2bc09204f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f9cdbc2f0e9489083cd3feba9102f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f39b1a1844f14a639feca16a9cbe2bef",
            "placeholder": "​",
            "style": "IPY_MODEL_e7d01eaa625b4b3d9b6879081111d899",
            "value": " 26.0/26.0 [00:00&lt;00:00, 604B/s]"
          }
        },
        "65013a9665bb4440a100e3b5944bbeff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "667a8a9ac3e845a6b1d6891f8baf8852": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd7186fcbfe54b0f9c5adbf467266adc",
            "placeholder": "​",
            "style": "IPY_MODEL_9a0df6faa8874ef98a9a7aaa4be8d2be",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "6721697c1c68466cbfbbdd16449372b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_667a8a9ac3e845a6b1d6891f8baf8852",
              "IPY_MODEL_09eeb6283403453a99bf8f9e92d66d5e",
              "IPY_MODEL_5f9cdbc2f0e9489083cd3feba9102f9a"
            ],
            "layout": "IPY_MODEL_7fe3c43d2a3f4cbd980c5a70f1d088a2"
          }
        },
        "677ccb9c83d946a68b8fe2180e840a0c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6834e1b57a844f558da7cc9b34806658": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1db28ea904b945a9945e5b6020a2b34a",
            "placeholder": "​",
            "style": "IPY_MODEL_530256dcba494eb58f1fceda4e265148",
            "value": "tokenizer.json: 100%"
          }
        },
        "6ca11b0c28384e1e96afb21dda3693df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46b9ef0f3784402484875828cb622a3a",
            "placeholder": "​",
            "style": "IPY_MODEL_8c656addc14347fda2e6b2cf36d28230",
            "value": "model.safetensors: 100%"
          }
        },
        "74d5ece3f3d244e4b4edf8f62b89f9c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6834e1b57a844f558da7cc9b34806658",
              "IPY_MODEL_7814329c9ed24a4f877396bfcfce0c1e",
              "IPY_MODEL_b453afe8c76b470f8f57be23ba501d7f"
            ],
            "layout": "IPY_MODEL_4cf617d36651419e9e734b7248aa9685"
          }
        },
        "763b2f16d27a49d5947fc6338de1a24a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76894766b40b4c959a5c296cb1a4dc1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7814329c9ed24a4f877396bfcfce0c1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_840184f87c7e4a78b4c09463c78df88f",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76894766b40b4c959a5c296cb1a4dc1f",
            "value": 1355256
          }
        },
        "7d87fe850b004e3582cde8f783492047": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fe3c43d2a3f4cbd980c5a70f1d088a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "840184f87c7e4a78b4c09463c78df88f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c656addc14347fda2e6b2cf36d28230": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "949175170ca6485d8c0bea03513d98f4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98bc657924a240c4b9924d49f06308f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_677ccb9c83d946a68b8fe2180e840a0c",
            "placeholder": "​",
            "style": "IPY_MODEL_e83132e7be1e461faf7a8f380152f376",
            "value": "merges.txt: 100%"
          }
        },
        "9a0df6faa8874ef98a9a7aaa4be8d2be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4316c8baa0545dc95e0fdaaaf6801b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b051fbbf949e4700915f46968bdfe117": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b37b4cf15b9b438cb1806a86bef24b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51835936b0ad48baa4aaed58ab48ad41",
            "placeholder": "​",
            "style": "IPY_MODEL_07fc45be19f94345868df48f7bd2f8ea",
            "value": " 665/665 [00:00&lt;00:00, 25.8kB/s]"
          }
        },
        "b453afe8c76b470f8f57be23ba501d7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_457f9aadc31741f3aa21c08588799283",
            "placeholder": "​",
            "style": "IPY_MODEL_dac2474a8fbc40eb84f158007777d0d7",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 4.74MB/s]"
          }
        },
        "bb98b4da6a184a5bb02bfcf7fb563545": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd7186fcbfe54b0f9c5adbf467266adc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd96943a8aa248e3aac5beea743fc541": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_949175170ca6485d8c0bea03513d98f4",
            "placeholder": "​",
            "style": "IPY_MODEL_ce305ff9cf3747239ac650123aec531a",
            "value": " 456k/456k [00:00&lt;00:00, 3.04MB/s]"
          }
        },
        "c75cf111d4864e67b1b450544ea8e4a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc85aa1ad6fa4c908fc828fd9ed3f489": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce305ff9cf3747239ac650123aec531a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4903471f6d4419c83f88d663f45d33c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dac2474a8fbc40eb84f158007777d0d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db457bcf5bfe4ba598d4a06e7b7882df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c75cf111d4864e67b1b450544ea8e4a2",
            "placeholder": "​",
            "style": "IPY_MODEL_cc85aa1ad6fa4c908fc828fd9ed3f489",
            "value": "vocab.json: 100%"
          }
        },
        "dbf01cd08ed64e9ea8c2cd7365d32e56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f50b105992847158401f5f7ecbdb4e2",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dc2fbf0e6df545fcbac35ece235ca5a0",
            "value": 548105171
          }
        },
        "dc2fbf0e6df545fcbac35ece235ca5a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2f64ccfefb245f28aabef5c8a555b07": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4de88b8c16c468c9dfe7554fc604314": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e7d01eaa625b4b3d9b6879081111d899": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e81e27dde3ec4c799529ad9915422466": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4903471f6d4419c83f88d663f45d33c",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e4de88b8c16c468c9dfe7554fc604314",
            "value": 665
          }
        },
        "e83132e7be1e461faf7a8f380152f376": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e897b57afab246a28aaa48c62938fb81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eacaa9b644224425b8c6bc245d1b04c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef52a8345ed9431cbe8eff251407d5a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db457bcf5bfe4ba598d4a06e7b7882df",
              "IPY_MODEL_f7c2f72cba374a5e8982fc64287e9246",
              "IPY_MODEL_2233d696f61b482898e2cb84115d57d7"
            ],
            "layout": "IPY_MODEL_fa0a452cee0a4a7f83452f6134b6e774"
          }
        },
        "f2fa0da3f123493d85ec704a0526b14a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f2c6bda17294c42ab70d46d8982ed89",
              "IPY_MODEL_e81e27dde3ec4c799529ad9915422466",
              "IPY_MODEL_b37b4cf15b9b438cb1806a86bef24b1a"
            ],
            "layout": "IPY_MODEL_18b3966d660246c7a8ec4045fa4e0582"
          }
        },
        "f39b1a1844f14a639feca16a9cbe2bef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7c2f72cba374a5e8982fc64287e9246": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2f64ccfefb245f28aabef5c8a555b07",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5866ff80fcc94ffbbeb170dfd5100148",
            "value": 1042301
          }
        },
        "fa0a452cee0a4a7f83452f6134b6e774": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
